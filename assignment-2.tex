\documentclass[a4paper,english,12pt]{article}
\input{preamble}

\title{STA-510 Statistical modelling and simulation}
\subtitle{Mandatory exercise 2}
\author{Christian Stigen}
\date{UiS, October \nth{19}, 2017}

\begin{document}
\maketitle
\section*{\normalsize{How to run the code}}
All the code for this exercise can be found in \texttt{assignment-2.R}. I have
made a single function for each problem. For example, to see the output of
problem 1 (d), execute the function \texttt{problem1d()}.  From the UNIX
command-line, you can run
\begin{verbatim}
Rscript -e 'pdf("problem1b.pdf");
            source("assignment-2.R");
            problem1b()' > problem1b.out
\end{verbatim}
to produce the textual output file \texttt{problem1b.out} and any plots in
\texttt{problem1b.pdf}. All plots and R output was generated automatically at
the same time as this document.

\problem{1 (a)}
\label{problem.1a}
Because
\begin{align*}
  \rho_{ab} &= \frac{\Cov(X_a, X_b)}{\sqrt{\Var(X_a)\Var(X_b)}} =
    \frac{\sigma_{ab}}{\sigma_a\sigma_b} \\
\end{align*}
we have that $\sigma_{ab} = \rho_{ab}\sigma_a\sigma_b$ and $\sigma_{aa} = 1$.
Furthermore, by definition $\Cov(X,X) = \E(X^2) - \E(X)^2 = \Var(X)$,
so that $\rho_{aa} = 1$ and $\sigma_{aa} = \Var(X_a) = \sigma_a^2$.

The \textbf{covariance matrix} is then
\[
  \Sigma\left(\textbf{X}\right) =
    \begin{bmatrix}
      \rho_{11} & \rho_{12} & \rho_{13} \\
      \rho_{21} & \rho_{22} & \rho_{23} \\
      \rho_{31} & \rho_{32} & \rho_{33} \\
    \end{bmatrix}
  =
    \begin{bmatrix}
      900 & -0.8 \cdot 30 \cdot 10 & 0.2 \cdot 30 \cdot 4 \\
      \rho_{12} & 100 & -0.3 \cdot 10 \cdot 4 \\
      \rho_{13} & \rho_{23} & 16 \\
    \end{bmatrix}
  =
    \begin{bmatrix}
       900 & -240 &  24 \\
      -240 &  100 & -12 \\
        24 &  -12 &  16 \\
    \end{bmatrix}
\]
while the \textbf{expectation vector} is
\[
  \bm{\mu} = \left( \mu_1 , \mu_2, \mu_3 \right)^T 
    = \left( 90, 48, 18 \right)^T
\]

\problem{1 (b)}
Output from R using \texttt{rmvnorm} \cite{mvtnorm}:
\VerbatimInput{problem1b.out}
We could also use the function \texttt{pmvnorm} to calculate the first two:
\VerbatimInput{problem1b_alternative.out}

\problem{1 (c)}
A top-tier character demands that \text{both} $X_1$ and $X_2$ are high at the
same time. Therefore, we should have the highest probability of getting a
top-tier character if they are positively correlated, so that a high $X_1$
implies a high $X_2$ and vice-versa.

\paragraph{(i)   $\rho_{12} =  -0.8$, $\rho_{13} = \rho_{23} = 0$}
\[
  \Sigma\left(\textbf{X}\right) =
    \begin{bmatrix}
      \rho_{11} & \rho_{12} & \rho_{13} \\
      \rho_{21} & \rho_{22} & \rho_{23} \\
      \rho_{31} & \rho_{32} & \rho_{33} \\
    \end{bmatrix}
  =
    \begin{bmatrix}
                         900 & -0.8 \cdot 30 \cdot 10 &    0 \\
      -0.8 \cdot 10 \cdot 30 &                    100 &    0 \\
                           0 &                      0 &   16 \\
    \end{bmatrix}
  =
    \begin{bmatrix}
                         900 &                   -240 &    0 \\
                        -240 &                    100 &    0 \\
                           0 &                      0 &   16 \\
    \end{bmatrix}
\]
This scenario should have the \textit{least probability} of a top-tier
character, because $X_1$ and $X_2$ are correlated negatively: When one is high,
the other tends to be low.

\paragraph{(ii)  $\rho_{12} =   0$, $\rho_{13} = \rho_{23} = 0$}
\[
  \Sigma\left(\textbf{X}\right) =
    \begin{bmatrix}
      \rho_{11} & \rho_{12} & \rho_{13} \\
      \rho_{21} & \rho_{22} & \rho_{23} \\
      \rho_{31} & \rho_{32} & \rho_{33} \\
    \end{bmatrix}
  =
    \begin{bmatrix}
                         900 &    0 \cdot 30 \cdot 10 &    0 \\
         0 \cdot 10 \cdot 30 &                    100 &    0 \\
                           0 &                      0 &   16 \\
    \end{bmatrix}
  =
    \begin{bmatrix}
                         900 &                      0 &    0 \\
                           0 &                    100 &    0 \\
                           0 &                      0 &   16 \\
    \end{bmatrix}
\]

\paragraph{(iii) $\rho_{12} = 0.8$, $\rho_{13} = \rho_{23} = 0$}
\[
  \Sigma\left(\textbf{X}\right) =
    \begin{bmatrix}
      \rho_{11} & \rho_{12} & \rho_{13} \\
      \rho_{21} & \rho_{22} & \rho_{23} \\
      \rho_{31} & \rho_{32} & \rho_{33} \\
    \end{bmatrix}
  =
    \begin{bmatrix}
                         900 &  0.8 \cdot 30 \cdot 10 &    0 \\
       0.8 \cdot 10 \cdot 30 &                    100 &    0 \\
                           0 &                      0 &   16 \\
    \end{bmatrix}
  =
    \begin{bmatrix}
                         900 &                    240 &    0 \\
                         240 &                    100 &    0 \\
                           0 &                      0 &   16 \\
    \end{bmatrix}
\]
This scenario should have the \textit{highest probability} of a top-tier
character, because the two values are positively correlated. That is, they both
tend to be either high or low at the same time.

\problem{1 (d)}
Output from R using \texttt{rmvnorm}:
\VerbatimInput{problem1d.out}
As we can see from the output, we seem to have reasoned correctly in problem 1
(c) about which scenarios should have the highest and lowest probability of
producing a top-tier character.

\problem{2 (a)}
The transform method in the lectures seem to first have been presented by
Ã‡inlar in \cite[p.~96]{cinlar}. While I do not have the book, the key theorem 
is reproduced in \cite{generating}. I have quoted that verbatim as
theorem \ref{theorem:cinlar} \vpageref[below]{theorem:cinlar}.

~\begin{theorem}
  \label{theorem:cinlar}
  Let $\Lambda(t), t \geqslant 0$ be a positive-valued, continuous,
  nondecreasing function. Then the random variables $T_1, T_2, \dots$ are event
  times corresponding to a nonhomogeneous Poisson process with expectation
  function $\Lambda(t)$ if and only if $\Lambda(T_1), \Lambda(T_2), \dots$ are
  the event times corresponding to a homogeneous Poisson process with rate one.
\end{theorem}

In other words, it relates a \textit{homogeneous} Poisson process with a
\textit{constant rate of one} to a non-homogeneous Poisson process. We can
actually go backwards by sampling event times from the homogeneous, rate 1
Poisson process, then go backwards through $\Lambda^{-1}$ to then generate
samples from the non-homogeneous process. See algorithm \vref{algorithm:nhpp}.

\begin{algorithm}
  \caption{Generates $n$ numbers for the non-homogeneous Poisson process (NHPP)}
  \label{algorithm:nhpp}
  \begin{algorithmic}[1]
    \Function{rnhpp}{$n, \Lambda^{-1}$}
      \Let{$s$}{vector of size $n$}
      \For{$i \gets 1 \textrm{ to } n$}
        \Let{$w$}{\Call{rpois}{$1$, lambda=$1$}} \Comment{Homogeneous Poisson sampler}
        \Let{$s_i$}{$\Lambda^{-1}(w)$}
      \EndFor
      \State \Return{$s$}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

In algorithm \vref{algorithm:nhpp}, $\Lambda^{-1}$ is the inverted rate
function, while $\textrm{rpois}$ is a function for generating numbers from a
homogeneous Poisson. The algorithm operates in a for-loop. In the
implementation, we will operate on vectors.

In practice, this means that the rate function $\Lambda(t)$ must be readily
reversible. That may not always be the case, but suffices for the current task.
We will start by finding it.

The intensity is given by $\lambda(t) = 14t^{0.4}$. We then have that
\begin{align*}
  \Lambda(t) &= \int_0^t{\lambda(u)}\, \textrm{d}u
    =  14\int_0^t{u^{0.4}}\, \textrm{d}u
    = \frac{14}{1.4}\left[ u^{1.4} \right]_0^t = 10t^{1.4} = 10t^{\frac{7}{5}}
\end{align*}
If we set $w = \Lambda(t)$, its inverse $\Lambda^{-1}(w) = t$ is given by
\begin{align*}
  w &= 10t^{\frac{7}{5}} \\
  w^{\frac{5}{7}} &= 10^{\frac{5}{7}}t \\
      \left( \frac{w}{10} \right)^{\frac{5}{7}} 
      &= 10^{\frac{7}{5}}w^{\frac{5}{7}} = t \\
  \Lambda^{-1}(w) &= t = 10^{\frac{7}{5}}w^{\frac{5}{7}}
\end{align*}

\paragraph{Sampling from the entire period $t \in [0,5]$}
Each $t$, represented as $w$ in algorithm \vref{algorithm:nhpp}, should cover the
entire period from 0 to 5. For example, when we plot the result, it would not
look good if we didn't plot for the entire range 0--5.

This is difficult to achieve in algorithm \vref{algorithm:nhpp}, since it
generates exactly $n$. I wouldn't want to change the algorithm, in fear of
disturbing the true distribution of numbers.

A naive way to correct this would be to simply sample a larger number of
values.

\problem{2 (b)}
See the plot in figure \vref{plot:2b}.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{problem2b.pdf}
  \caption{Cumulative failures in the first five years.}
  \label{plot:2b}
\end{figure}

\problem{2 (c)}
\problem{2 (d)}
\problem{2 (e)}
\problem{2 (f)}
\problem{2 (g)}
\problem{2 (h)}
\problem{2 (i)}

\problem{3 (a)}
The basic idea of Monte Carlo integration is to approximate an integral by
sampling. By drawing random numbers in the plane, we can easily determine if
the point falls above or below the integrand line by inserting the random $x$
value in the integrand function. The integral, or area under the curve, should
then be approximated with the ratio of points that fall above and below the
line.

This will be a win in situations where the integral is impossible, hard or
computationally expensive to perform --- for example, multi-dimensional
integrals.

The \textit{crude Monte Carlo integration} is given by
\[
  \hat{\theta}_{\textrm{CMC}} = \frac{b-a}{n} \sum_{i=1}^{n} g(X_i) =
  (b-a)\overline{g(X)}
\]
Here, $f(x) = \frac{1}{b-a}$ is the density function, and $n$ is the number of
samples drawn from $X \sim U[a,b]$. By the law of large numbers,
$\hat{\theta}_{\textrm{CMC}} \to \theta$ as $n \to \infty$. The derivation of the above
equation is given in the lecture notes.

So, to perform crue Monte Carlo integration, we pick $n$ random numbers and
keep track of how many are above and below the integrand line given by $g(x)$.
The ratio, multiplied with $(b-a)$ will then give us
$\hat{\theta}_{\textrm{CMC}}$.

\problem{3 (b)}
\problem{3 (c)}
\problem{3 (d)}

\clearpage
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,assignment-2}

\end{document}
