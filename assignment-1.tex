\documentclass[a4paper,english,12pt]{article}
\input{preamble}

\title{STA-510 Statistical modelling and simulation}
\subtitle{Mandatory exercise 1}
\author{Christian Stigen}
\date{UiS, September \nth{21}, 2017}

\begin{document}
\maketitle

\problem{1 (a)}
The probability density function is given in \cite{walpole} as
\[
  f(x) =
    \begin{cases}
      \displaystyle
        \frac{1}{\beta} e^{-\frac{x}{\beta}} & x > 0  \\
        0 & \text{elsewhere}
    \end{cases}
\]
We then have that
\[
  P(X \leqslant x) = \int_{-\infty}^{x} f(t)\, \mathrm{d}t 
    = \left[ -e^{-\frac{t}{\beta}} \right]_{0}^{x} = 1 - e^{-\frac{x}{\beta}}
\]

\problem{1 (a i)}
\[
  P(X > 4000) = 1 - P(X \leqslant 4000) = e^{-\frac{4000}{5000}} \approx 0.449
\]

\problem{1 (a ii)}
\[
  P(4000 \leqslant X \leqslant 6000) =
    P(X \leqslant 6000) - P(X \leqslant 4000) =
       e^{-\frac{4000}{5000}} - e^{-\frac{6000}{5000}}
       \approx 0.148
\]
Note that for continuous density functions, $P(X=x) = 0$. Therefore I have not
been diligent in the use of the less-than-or-equal symbols here.

\problem{1 (b)}
Output from R:
\VerbatimInput{problem1b.out}

\problem{1 (c)}
Output from R:
\VerbatimInput{problem1c.out}
We can clearly see that more samples gets us closer to the computed value.

\problem{1 (d)}
Output from R:
\VerbatimInput{problem1d.out}

\problem{1 (e)}
Output from R:
\VerbatimInput{problem1e.out}

\problem{2 (a)}
For each round, we draw seven random numbers from 1--34. We count how many
draws contain at least two consecutive number ($c$) and divide by how many
total draws we have made ($n$). The probability will then be
\[
  P(\text{contains two or more consecutive numbers}) = \frac{c}{n}
\]
% TODO: Find how many sims to be 95% that the error is at most 0.01. See slides
% for this!
We have
\begin{align*}
  \text{ME} &= z\sqrt{\frac{\hat{p}(1-\hat{p})}{n}} \\
  \left(\frac{\text{ME}}{z}\right)^2 &= \frac{\hat{p}(1-\hat{p})}{n} \\
  n &= \ceil*{ \hat{p}(1-\hat{p}) \frac{z^2}{\text{ME}^2} }
\end{align*}
where $\ceil{\dots}$ is the ceiling function.

I wrote a test program that seems to indicate that $\hat{p} = 0.779$. The
z-value must be 1.96 for a 95\%{} interval, and we have the margin of error
$\text{ME} = 0.01$, which gives us
\[
  n = 6614
\]
That suggests that we should have around 6614 samples.

\problem{2 (b)}
Output from R:
\VerbatimInput{problem2b.out}

\problem{3 (a)}
\paragraph{Problem} We want to sample x-values whose distribution is given by a
probability density function (PDF) is $f(x)$.

\paragraph{Solution} We use the \textit{inverse transform method}
\cite{wiki:inverse.transform.method}: Since any the values given by the PDF is
within 0--1, we use a uniform pseudo-random number generator to select a value
in the interval 0--1. We then find which x-value will give this value by
finding the inverse of the cumulative density function (CDF) $g$.

The CDF is given by
\begin{align*}
  g(x) & = \int_{-\infty}^{x} f(x)\, \mathrm{d}t 
     = \left[ -e^{-\frac{t^2}{2\theta^2}} \right]_0^{x} = 
     1 - e^{-\frac{x^2}{2\theta^2}}, \text{ where } x>0 \text{ and } \theta > 0
\end{align*}
We now need to find $g^{-1}(u)$ for
\begin{align*}
  g(g^{-1}(u)) &= 1 - e^{-\frac{g^{-1}(u)^2}{2\theta^2}} = u \\
   e^\frac{g^{-1}(u)^2}{2\theta^2}  &= \frac{1}{1 - u} \\
   g^{-1}(u)^2  &= 2\theta^2\log{\left(\frac{1}{1 - u}\right)} \\
   g^{-1}(u)  &= \pm\theta\sqrt{2\log{\left(\frac{1}{1 - u}\right)}} \\
\end{align*}
In solving these, I got a minus sign under the square root. However, taking the
logarithm of a number less than zero will of course yield a negative number,
cancelling out the signs: Thus, the following two solutions are equal:
\[
  \theta\sqrt{-2\log{(1-u)}} = \theta\sqrt{2\log{\left(\frac{1}{1-u}\right)}}\,
  \text{ where } u \in \left[0,1\right>
\]
For the above two equations, the left one may be more numerically stable when
implemented in computers. It also avoids one division. In fact, this is the one
that was chosen in the implementation of \texttt{rrayleigh} in the
\texttt{VGAM} package \cite{github:vgam}.

Since $x > 0$ we can only have positive square roots. We get
\begin{align*}
    x &= g^{-1}(u) = \theta\sqrt{2\log{\left(\frac{1}{1 - u}\right)}}
   \text{ where } x>0\, , \theta>0\, , u \in \left[0,1\right>
   \\
\end{align*}%
The algorithm to generate one sample will then be
\begin{itemize}
  \item set $u = \mathrm{uniform}(0,1)$ where $u<1$
  \item return $x = g^{-1}(u)$, where $g^{-1}$ as defined above.
\end{itemize}

\problem{3 (b)}
A histogram of Rayleigh samples is given in figure \vref{plot:3b}, while a
comparison between the expected value, variance and their sample counterparts
are given in table \vref{table:3b}.

\input{problem3b.out}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{problem3b.pdf}
  \caption{Rayleigh samples for problem 3 (b) with $\theta=1.78$. The expected
  value and PDF are indicated by the red, dotted lines.}
  \label{plot:3b}
\end{figure}

\problem{3 (c)}
One simulation: Set $\theta=1.3$ and take Rayleigh 200 samples. Return 0 if all
waves are less than or equal to five meters, 1 if not. We then perform a large
number of simulations and divide the sum of each simulation by the number of
simulations made.

I've been experimenting with an alternative way: Take $200n$ samples where $n$
is the number of simulations. Then count how many waves are larger than five
meters, and divide by $n$. The rationale is that each wave is independent, and
because of the law of large values, we should be able to ignore if any wave
occurs in a batch of 200 or not. While this is much faster to computer in R, it
does give just slightly different results. This is included in the output in
problem 3 (d) as \texttt{simulations v2}, but I prefer not to use that.

\problem{3 (d)}
Output from R:
\VerbatimInput{problem3d.out}

\problem{3 (e)}
We \textit{uniformly} sample $n$ points consiting of an $x \in [1.5, 3]$ and $y
\in [0, 1]$. We then check that each point is inside the region defined by the
triangle PDF and the axis. Points outside are rejected, points inside are
accepted and used as samples.  Because of the triangle shape, it will be more
likely to get values around the most expected wave height of 2, while values
near the extremes $1.5$ and $3$ will be less likely to have been accepted.

With more details, we have $a=1.5$, $c=2$ and $b=3$. The height at $c$ is
$\frac{2}{b-a} = \frac{4}{3}$. In our algorithm, we thus check that the point's $x$
value is less than or equal to $c$. If it is, it will be accepted if its $y$
value is less than or equal to $\frac{8}{3}x - 4$. Likewise, for values higher
than $c$, we check against $-\frac{4}{3} + 4$.

\paragraph{Algorithm}
\begin{itemize}
  \item Let $a=\text{minimum wave height}$, $b=\text{maximum wave height}$ and
    $c=\text{expected wave height}$.
  \item Let $l(x) = \frac{2}{(b-a)(c-a)}$  and $r(x) = \frac{2}{(b-a)(b-c)}$
    (left and right lines)
  \item Uniformly pick a random point $x \in [a, b]$ and $y \in [0, \frac{2}{b-a}]$.
  \item If $x \leqslant c$, accept if $y \in \left[0, l(x)\right]$
  \item If $x > c$, accept if $y \in \left[0, r(x)\right]$
  \item Else reject
\end{itemize}

\problem{3 (f)}
See figure \vref{plot:3f}.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{problem3f.pdf}
  \caption{Acceptance-rejection sampling from the triangle distribution with
  $a=1.5$, $b=3$ and $c=2$.}
  \label{plot:3f}
\end{figure}

\problem{3 (g)}
\problem{3 (h)}
\problem{3 (i)}

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,references}

\end{document}
