\documentclass[a4paper,english,12pt]{article}
\input{preamble}

\title{STA-510 Statistical modelling and simulation}
\subtitle{Mandatory exercise 1}
\author{Christian Stigen}
\date{UiS, September \nth{21}, 2017}

\begin{document}
\maketitle

\problem{1 (a)}
The probability density function is given in \cite{walpole} as
\[
  f(x) =
    \begin{cases}
      \displaystyle
        \frac{1}{\beta} e^{-\frac{x}{\beta}} & x > 0  \\
        0 & \text{elsewhere}
    \end{cases}
\]
We then have that
\[
  P(X \leqslant x) = \int_{-\infty}^{x} f(t)\, \mathrm{d}t 
    = \left[ -e^{-\frac{t}{\beta}} \right]_{0}^{x} = 1 - e^{-\frac{x}{\beta}}
\]

\problem{1 (a i)}
\[
  P(X > 4000) = 1 - P(X \leqslant 4000) = e^{-\frac{4000}{5000}} \approx 0.449
\]

\problem{1 (a ii)}
\[
  P(4000 \leqslant X \leqslant 6000) =
    P(X \leqslant 6000) - P(X \leqslant 4000) =
       e^{-\frac{4000}{5000}} - e^{-\frac{6000}{5000}}
       \approx 0.148
\]
Note that for continuous density functions, $P(X=x) = 0$, so we don't have
to be exact with the equals-or-less symbols.

\problem{1 (b)}
Output from R:
\VerbatimInput{problem1b.out}

\problem{1 (c)}
Output from R:
\VerbatimInput{problem1c.out}
We definitely see that the larger number of samples, the closer we
get to the theoretical correct answer. However, it also becomes more costly
to computate, at least the way we do it here. The winnings for doing it this
way will only be seen when the underlying function is not known (for example,
it may be hard or impossible to work out algebraically) or computationally very
expensive.

\problem{1 (d)}
Output from R:
\VerbatimInput{problem1d.out}

\problem{1 (e)}
Output from R:
\VerbatimInput{problem1e.out}

\problem{2 (a)}
For each round, we draw seven random numbers between one and 34. We count how
many draws contain at least two consecutive number ($c$) and divide by how many
total draws we have made ($n$). The chance will then be
\[
  P(\text{contains two or more consecutive numbers}) = \frac{c}{n}
\]
% TODO: Find how many sims to be 95% that the error is at most 0.01. See slides
% for this!
We have
\begin{align*}
  \text{ME} &= z\sqrt{\frac{\hat{p}(1-\hat{p})}{n}} \\
  \left(\frac{\text{ME}}{z}\right)^2 &= \frac{\hat{p}(1-\hat{p})}{n} \\
  n &= \ceil*{ \hat{p}(1-\hat{p}) \frac{z^2}{\text{ME}^2} }
\end{align*}
where $\ceil{\dots}$ is the ceiling function.

I wrote a test program that seems to indicate that $\hat{p} = 0.779$, so we can
use that and see what we get.  The z-value must be 1.96 for a 95\%{} interval,
and we have the margin of error $\text{ME} = 0.01$, which gives us
\[
  n = 6614
\]
That suggests that we should have around 6614 samples.

\problem{2 (b)}
Output from R:
\VerbatimInput{problem2b.out}

\problem{3 (a)}
\paragraph{Problem} We want to sample x-values whose distribution is given by a
probability density function (PDF) is $f(x)$.
\paragraph{Solution} We use the \textit{inverse transform method}: Since any
the values given by the PDF is within 0--1, we use a uniform pseudo-random
number generator to select a value in the interval 0--1. We then find which
x-value will give this value by finding the inverse of the cumulative density
function (CDF) $g$.

The CDF is given by
\begin{align*}
  g(x) & = \int_{-\infty}^{x} f(x)\, \mathrm{d}t 
     = \left[ -e^{-\frac{t^2}{2\theta^2}} \right]_0^{x} = 
     1 - e^{-\frac{x^2}{2\theta^2}}, \text{ where } x>0 \text{ and } \theta > 0
\end{align*}
We now need to find $g^{-1}(u)$ for
\begin{align*}
  g(g^{-1}(u)) &= 1 - e^{-\frac{g^{-1}(u)^2}{2\theta^2}} = u \\
   e^\frac{g^{-1}(u)^2}{2\theta^2}  &= \frac{1}{1 - u} \\
   g^{-1}(u)^2  &= 2\theta^2\log{\left(\frac{1}{1 - u}\right)} \\
   g^{-1}(u)  &= \pm\theta\sqrt{2\log{\left(\frac{1}{1 - u}\right)}} \\
\end{align*}
Since $x > 0$ we can only have positive square roots. We get
\begin{align*}
    x &= g^{-1}(u) = \theta\sqrt{2\log{\left(\frac{1}{1 - u}\right)}}
   \text{ where } x>0\, , \theta>0\, , u \in \left[0,1\right>
   \\
\end{align*}%
The algorithm to generate one sample will then be
\begin{itemize}
  \item set $u = \mathrm{uniform}(0,1)$ where $u<1$
  \item return $x = g^{-1}(u)$, where $g^{-1}$ as defined above.
\end{itemize}

\problem{3 (b)}
A histogram of Rayleigh samples is given in figure \vref{plot:3b}, while a
comparison between the expected value, variance and their sample counterparts
are given in table \vref{table:3b}.

\input{problem3b.out}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{problem3b.pdf}
  \caption{Rayleigh samples for problem 3 (b) with $\theta=1.78$. The expected
  value and PDF are indicated by the red, dotted lines.}
  \label{plot:3b}
\end{figure}

\problem{3 (c)}
\problem{3 (d)}
\problem{3 (e)}
\problem{3 (f)}
\problem{3 (g)}
\problem{3 (h)}
\problem{3 (i)}

\bibliography{references}
\bibliographystyle{ieeetr}

\end{document}
